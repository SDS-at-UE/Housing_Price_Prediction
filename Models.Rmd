---
title: "Models"
author: "Gideon Wolf, Jeremiah Sagers"
date: "4/15/2024"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

### From ReadData.R
library(tidyverse)
library(mice)
library(xts)
library(ggplot2)
library(glmnet)
library(caret)
library(lars)

# Read in data, handle NAs
house <- read.csv("train.csv")

NAtoNone <- c(2,3,7,10,24,25,26,31,32,33,34,36,54,56,58,59,61,64,65,73,74,75,79)
for (i in NAtoNone) {
  housetmp <- house
  housetmp[i][is.na(housetmp[i])] <- "None"
  house <- housetmp
}
house <- house[-1380,]

house <- house %>% mutate_if(is.character, as.factor)
house <- house %>% mutate_at(c('MSSubClass','MoSold'), as_factor) 

YrMoSold <- do.call(paste, c(sep='',list(house$YrSold),list(rep("-", times = length(house$YrSold))),list(house$MoSold),list(rep("-01", times = length(house$YrSold)))))
YrMoSold <- as_date(YrMoSold)
house <- as.data.frame(append(house, list(YrMoSold = YrMoSold), after = 78))

# Take out GarageYrBlt
house <- house[-60]

# Imputation
numhouse <- select_if(house, is.numeric)
imputed_house <- mice(numhouse, 
                      m = 10,  
                      method = 'pmm', 
                      seed = 1)

set.seed(1)
imphouse <- complete(imputed_house)
housetmp <- house
s = 1
for (i in names(imphouse)[2:length(names(imphouse))]) {
  housetmp[i] <- imphouse[i]
}
house <- housetmp
###
```

Working on making Linear Regression, Lasso, Ridge, 

```{r}
set.seed(66)
training <- mutate(house, id = row_number())
train <- sample_frac(training, .75)
valid <- anti_join(training, train, by = 'id')
train <- dplyr::select(train, -id)
valid <- dplyr::select(valid, -id)

x_train <- model.matrix(SalePrice~.-1, train)[,-81]
y_train <- train[81]$SalePrice
x_test <- model.matrix(SalePrice~.-1, valid)[,-81]
y_test <- valid[81]$SalePrice
```

## Using GLMNet
```{r}
grid = 10^seq(10, -2, length = 100)

cvlas <- cv.glmnet(x_train,y_train, alpha=1,nfolds = 20)
minlam = cvlas$lambda.min
minlam

glmlas <- glmnet(x_train,y_train,family = "gaussian", alpha=1, lambda = grid) # lasso regression, when lambda = minlam, training rsq is reasonable (i.e. not -49), but plot(glmlas) looking at lambda does not work.

laspred <- predict(glmlas, s =minlam, newx = x_test)
cvpred <- predict(cvlas, s =minlam, newx = x_test)
mean((laspred - y_test)^2)
mean((cvpred - y_test)^2)
# predict(glmlas, type = "coefficients", s=minlam)
plot(glmlas,xvar="lambda",label=TRUE)
plot(glmlas)
plot(cvlas)

# Dr. Khormali found: https://drbeane.github.io/_pages/courses/mth345/24%20-%20Lasso%20and%20Ridge.nb.html
y_train_pred_lasso <- predict(cvlas, x_train)
sse <- sum((y_train - y_train_pred_lasso)^2)
sst <- sum((y_train - mean(y_train))^2)
training_rsq <- 1 - sse / sst
y_test_pred_lasso <- cvpred
sse <- sum((y_test - y_test_pred_lasso)^2)
sst <- sum((y_test - mean(y_test))^2)
testing_rsq <- 1 - sse / sst
lasso_rsq <- c(training_rsq, testing_rsq)
names(lasso_rsq) <- c('Training', 'Testing')
lasso_rsq


y_train_pred_lasso <- predict(glmlas, x_train)
sse <- sum((y_train - y_train_pred_lasso)^2)
sst <- sum((y_train - mean(y_train))^2)
training_rsq <- 1 - sse / sst
y_test_pred_lasso <- laspred
sse <- sum((y_test - y_test_pred_lasso)^2)
sst <- sum((y_test - mean(y_test))^2)
testing_rsq <- 1 - sse / sst
lasso_rsq <- c(training_rsq, testing_rsq)
names(lasso_rsq) <- c('Training', 'Testing')
lasso_rsq

# https://stats.stackexchange.com/questions/25817/is-it-possible-to-calculate-aic-and-bic-for-lasso-regression-models
fit <- glmlas
tLL <- fit$nulldev - deviance(fit)
k <- fit$df
n <- fit$nobs
AICc <- -tLL+2*k+2*k*(k+1)/(n-k-1)
# AICc
BIC<-log(n)*k - tLL
# BIC
```

<!-- ## Using Lars (Throws error for mode/s) -->
<!-- ```{r} -->
<!-- ## https://stats.stackexchange.com/questions/58531/using-lasso-from-lars-or-glmnet-package-in-r-for-variable-selection -->
<!-- cv <- lars::cv.lars(x_train, y_train, plot.it = FALSE) -->
<!--   ideal_l1_ratio <- cv$index[which.max(cv$cv - cv$cv.error <= min(cv$cv))] -->
<!--   obj <- lars(x_train, y_train, type="lasso") -->
<!--   scaled_coefs <- scale(obj$beta, FALSE, 1 / obj$normx) -->
<!--   l1 <- apply(X = scaled_coefs, MARGIN = 1, FUN = function(x) sum(abs(x))) -->
<!--   coef(obj)[which.max(l1 / tail(l1, 1) > ideal_l1_ratio),] -->

<!-- p <- predict(obj, x_test, "fit", mode = "norm") -->
<!-- # Returns following error: how to make s in range?  -->
<!-- # Error in predict.lars(obj, x_test, "fit", mode = "norm") :  -->
<!-- # Argument s out of range -->

<!-- ``` -->

```{r}

```


